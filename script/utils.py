# Importation des biblioth√®ques n√©cessaires
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
from io import BytesIO
import streamlit as st
from scipy import stats as ss
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import joblib
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px


def create_plotly_pie_chart(labels, sizes):
    fig = px.pie(
        names=labels,
        values=sizes,
        title="R√©partition des valeurs",
        color_discrete_sequence=px.colors.sequential.Viridis,
    )
    fig.update_traces(textposition="inside", textinfo="percent+label")
    fig.update_layout(title_font_size=20)
    return fig


def create_seaborn_bar_chart(labels, values):
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.barplot(x=labels, y=values, palette="viridis", ax=ax)
    ax.set_title("R√©partition des donn√©es par cat√©gorie", fontsize=14, weight="bold")
    ax.set_xlabel("Cat√©gories", fontsize=12)
    ax.set_ylabel("Valeurs", fontsize=12)
    plt.xticks(rotation=45)
    plt.tight_layout()
    return fig


def create_plotly_histogram(values):
    fig = px.histogram(
        values,
        nbins=20,
        title="Distribution des valeurs",
        color_discrete_sequence=["skyblue"],
    )
    fig.update_layout(
        xaxis_title="Valeurs", yaxis_title="Fr√©quence", title_font_size=20
    )
    return fig


def create_plotly_line_chart(x, y):
    fig = px.line(
        x=x, y=y, title="√âvolution des valeurs", markers=True, line_shape="spline"
    )
    fig.update_layout(
        xaxis_title="Cat√©gories", yaxis_title="Valeurs", title_font_size=20
    )
    return fig


# Cr√©er un graphique en pgn
def save_fig_as_png(fig, filename):
    buf = BytesIO()
    fig.savefig(buf, format="png")
    st.download_button(
        label="T√©l√©charger l'image",
        data=buf,
        file_name=f"{filename}.png",
        mime="image/png",
    )


# Fonction pour charger un mod√®le sp√©cifique
def load_model(model_option, target_variable):
    models = {
        "Conso_5_usages_√©_finale": {
            "XGBoost": "../models/consommation_xgboost_model.pkl",
            "Arbre de D√©cision": "../models/consommation_arbre_de_decision_model.pkl",
            "For√™t Al√©atoire": "../models/consommation_random_forest.pkl",
        },
        "Etiquette_DPE": {
            "K-nearest neighbors": "../models/etiquette_knn_model.pkl",
            "Arbre de D√©cision": "../models/etiquette_arbre_de_decision_model.pkl",
            "For√™t Al√©atoire": "../models/etiquette_random_forest_model.pkl",
        },
    }
    model_file = models[target_variable][model_option]
    model = joblib.load(model_file)
    return model


# Entra√Æner et sauvegarder les mod√®les
def train_and_save_models(data_path, target_variable):
    # Charger les donn√©es
    data = pd.read_csv(data_path)

    if target_variable == "Consommation √ânerg√©tique":
        X = data[
            [
                "Surface_habitable_logement",
                "Ubat_W/m¬≤_K",
                "Etiquette_DPE",
                "Type_√©nergie_principale_chauffage",
            ]
        ]
        y = data["Conso_5_usages_√©_finale"]

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        xboost = XGBRegressor()
        xboost.fit(X_train, y_train)
        joblib.dump(xboost, "consommation_xgboost_model.pkl")

        dec_tree = DecisionTreeRegressor()
        dec_tree.fit(X_train, y_train)
        joblib.dump(dec_tree, "consommation_arbre_de_decision_model.pkl")

        rand_forest = RandomForestRegressor(n_estimators=100)
        rand_forest.fit(X_train, y_train)
        joblib.dump(rand_forest, "consommation_random_forest_model.pkl")

    elif target_variable == "√âtiquette DPE":
        X = data[
            [
                "Conso_chauffage_√©_primaire",
                "Conso_5_usages_√©_finale",
                "Emission_GES_5_usages_par_m¬≤",
                "Etiquette_GES",
                "Co√ªt_√©clairage",
            ]
        ]
        y = data["Etiquette_DPE"]

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )

        knn = KNeighborsClassifier(n_neighbors=5)
        knn.fit(X_train, y_train)
        joblib.dump(knn, "etiquette_knn_model.pkl")

        dec_tree = DecisionTreeClassifier()
        dec_tree.fit(X_train, y_train)
        joblib.dump(dec_tree, "etiquette_arbre_de_decision_model.pkl")

        rand_forest = RandomForestClassifier(n_estimators=100)
        rand_forest.fit(X_train, y_train)
        joblib.dump(rand_forest, "etiquette_random_forest_model.pkl")

    print(f"Mod√®les pour {target_variable} entra√Æn√©s et sauvegard√©s avec succ√®s.")


# Fonction pour r√©entra√Æner le mod√®le avec les nouveaux param√®tres
def retrain_model(
    model_option, params, prediction_type, data_path="../data/preprocessed_data.csv"
):
    # Charger les donn√©es
    data = pd.read_csv(data_path)

    # S√©lection des caract√©ristiques et du mod√®le en fonction du type de pr√©diction
    if prediction_type == "√âtiquette DPE":
        X = data[
            [
                "Conso_chauffage_√©_primaire",
                "Conso_5_usages_√©_finale",
                "Emission_GES_5_usages_par_m¬≤",
                "Etiquette_GES",
                "Co√ªt_√©clairage",
            ]
        ]
        y = data["Etiquette_DPE"]
        # S√©lection du mod√®le sp√©cifique pour l'√âtiquette DPE
        if model_option == "K-nearest neighbors":
            model = KNeighborsClassifier(**params)
            model_filename = "etiquette_knn_model.pkl"
        elif model_option == "For√™t Al√©atoire":
            model = RandomForestClassifier(**params)
            model_filename = "etiquette_random_forest_model.pkl"
        elif model_option == "Arbre de D√©cision":
            model = DecisionTreeClassifier(**params)
            model_filename = "etiquette_arbre_de_decision_model.pkl"
    elif prediction_type == "Consommation √ânerg√©tique":
        X = data[
            [
                "Surface_habitable_logement",
                "Ubat_W/m¬≤_K",
                "Etiquette_DPE",
                "Type_√©nergie_principale_chauffage",
            ]
        ]
        y = data["Conso_5_usages_√©_finale"]
        # S√©lection du mod√®le sp√©cifique pour la Consommation √ânerg√©tique
        if model_option == "XGBoost":
            model = XGBRegressor(**params)
            model_filename = "consommation_xgboost_model.pkl"
        elif model_option == "For√™t Al√©atoire":
            model = RandomForestRegressor(**params)
            model_filename = "consommation_random_forest_model.pkl"
        elif model_option == "Arbre de D√©cision":
            model = DecisionTreeRegressor(**params)
            model_filename = "consommation_arbre_de_decision_model.pkl"

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    # Entra√Æner le mod√®le
    model.fit(X_train, y_train)

    # Sauvegarder le mod√®le
    joblib.dump(model, model_filename)
    return model


# Mapping des valeurs pour les encodages
encoding_maps = {
    "Type_b√¢timent": {"Maison": 0.0, "Appartement": 1.0, "Immeuble": 2.0},
    "Qualit√©_isolation_enveloppe": {
        "insuffisante": 0.0,
        "moyenne": 1.0,
        "bonne": 2.0,
        "tr√®s bonne": 3.0,
    },
    "Etiquette_GES": {
        "A": 0.0,
        "B": 1.0,
        "C": 2.0,
        "D": 3.0,
        "E": 4.0,
        "F": 5.0,
        "G": 6.0,
    },
    "Etiquette_DPE": {
        "A": 0.0,
        "B": 1.0,
        "C": 2.0,
        "D": 3.0,
        "E": 4.0,
        "F": 5.0,
        "G": 6.0,
    },
    "Type_installation_chauffage": {
        "individuel": 0.0,
        "collectif": 1.0,
        "mixte (collectif-individuel)": 2.0,
    },
    "Type_√©nergie_n¬∞1": {
        "Gaz naturel": 0.0,
        "√âlectricit√©": 1.0,
        "R√©seau de Chauffage urbain": 2.0,
        "Bois ‚Äì Granul√©s (pellets) ou briquettes": 3.0,
        "Fioul domestique": 4.0,
    },
    "M√©thode_application_DPE": {
        "dpe appartement individuel": 0.0,
        "dpe appartement g√©n√©r√© √† partir des donn√©es DPE immeuble": 1.0,
        "dpe maison individuelle": 2.0,
        "dpe issu d'une √©tude thermique r√©glementaire RT2012 b√¢timent : appartement": 3.0,
        "dpe issu d'une √©tude thermique r√©glementaire RT2012 b√¢timent : maison individuelle": 4.0,
        "dpe immeuble collectif": 5.0,
    },
    "Qualit√©_isolation_murs": {
        "insuffisante": 0.0,
        "moyenne": 1.0,
        "bonne": 2.0,
        "tr√®s bonne": 3.0,
    },
    "Qualit√©_isolation_plancher_bas": {
        "insuffisante": 0.0,
        "moyenne": 1.0,
        "bonne": 2.0,
        "tr√®s bonne": 3.0,
    },
    "Qualit√©_isolation_menuiseries": {
        "insuffisante": 0.0,
        "moyenne": 1.0,
        "bonne": 2.0,
        "tr√®s bonne": 3.0,
    },
}


# Fonction d'encodage des donn√©es d'entr√©e
def encode_input_data(input_data):
    encoded_data = {}
    for column, value in input_data.items():
        if column in encoding_maps:
            encoded_data[column] = float(encoding_maps[column].get(value, None))
        else:
            encoded_data[column] = value
    return encoded_data


def predict(type_prediction, model, **kwargs):
    """
    Fonction de pr√©diction unique pour l'√©tiquette DPE ou la consommation √©nerg√©tique.
    type_prediction : str - "√âtiquette DPE" ou "Consommation √ânerg√©tique"
    model : mod√®le de pr√©diction entra√Æn√©
    kwargs : caract√©ristiques du logement n√©cessaires pour la pr√©diction
    """
    if type_prediction == "Consommation √ânerg√©tique":
        # Encodage des donn√©es d'entr√©e
        encoded_data = encode_input_data(kwargs)

        # Extraire les variables n√©cessaires pour la pr√©diction de la consommation
        columns = [
            "Type_b√¢timent",
            "Qualit√©_isolation_enveloppe",
            "Etiquette_GES",
            "Surface_habitable_logement",
            "Etiquette_DPE",
            "Type_installation_chauffage",
            "Ubat_W/m¬≤_K",
            "Qualit√©_isolation_murs",
            "Type_√©nergie_n¬∞1",
            "Qualit√©_isolation_plancher_bas",
            "M√©thode_application_DPE",
            "Qualit√©_isolation_menuiseries",
        ]

        X = pd.DataFrame(
            [
                [
                    encoded_data.get("Type_b√¢timent"),
                    encoded_data.get("Qualit√©_isolation_enveloppe"),
                    encoded_data.get("Etiquette_GES"),
                    encoded_data.get("Surface_habitable_logement"),
                    encoded_data.get("Etiquette_DPE"),
                    encoded_data.get("Type_installation_chauffage"),
                    encoded_data.get("Ubat_W/m¬≤_K"),
                    encoded_data.get("Qualit√©_isolation_murs"),
                    encoded_data.get("Type_√©nergie_n¬∞1"),
                    encoded_data.get("Qualit√©_isolation_plancher_bas"),
                    encoded_data.get("M√©thode_application_DPE"),
                    encoded_data.get("Qualit√©_isolation_menuiseries"),
                ]
            ],
            columns=columns,
        )

        # Pr√©dire la consommation √©nerg√©tique
        prediction = model.predict(X)[0]
        return prediction
    elif type_prediction == "√âtiquette DPE":
        # Encodage des donn√©es d'entr√©e
        encoded_data = encode_input_data(kwargs)

        # Extraire les variables n√©cessaires pour la pr√©diction de l'√©tiquette DPE
        columns = [
            "Conso_5_usages_par_m¬≤_√©_primaire",
            "Conso_5_usages/m¬≤_√©_finale",
            "Emission_GES_5_usages_par_m¬≤",
            "Etiquette_GES",
            "Co√ªt_√©clairage",
        ]

        X = pd.DataFrame(
            [
                [
                    encoded_data.get("Conso_5_usages_par_m¬≤_√©_primaire"),
                    encoded_data.get("Conso_5_usages/m¬≤_√©_finale"),
                    encoded_data.get("Emission_GES_5_usages_par_m¬≤"),
                    encoded_data.get("Etiquette_GES"),
                    encoded_data.get("Co√ªt_√©clairage"),
                ]
            ],
            columns=columns,
        )

        # Pr√©dire l'√©tiquette DPE
        prediction = model.predict(X)[0]
        return prediction


def calculate_kpis(data):
    kpis = {}

    # KPI 1: Consommation moyenne des logements
    moyenne_conso = data["Conso_5_usages_√©_finale"].mean()
    kpis["conso_energetique_moyenne"] = moyenne_conso

    # KPI 2: Pourcentage de logements au-dessus de la consommation moyenne
    kpis["pct_logements_au_dessus_moyenne"] = (
        data["Conso_5_usages_√©_finale"] > moyenne_conso
    ).mean() * 100

    # KPI 3: Taux de logements ¬´ passoires √©nerg√©tiques ¬ª (√©tiquette DPE F ou G)
    passoires_energetiques = data["Etiquette_DPE"].isin(["F", "G"]).sum()
    kpis["taux_passoires_energetiques"] = (passoires_energetiques / len(data)) * 100

    # KPI 4: Etiquette DPE la plus fr√©quente
    kpis["etiquette_dpe_frequente"] = data["Etiquette_DPE"].mode()[0]

    return kpis


def afficher_kpis(kpis):
    st.title("Indicateurs Cl√©s de Performance (KPI)")
    st.markdown("---")

    # Noms lisibles pour les KPI avec textes r√©duits
    kpis_readable = {
        "conso_energetique_moyenne": "Consommation Energ√©tique Moyenne (en kWh/logement)",
        "pct_logements_au_dessus_moyenne": " Poucentage de Logements au-dessus de la Moyenne",
        "taux_passoires_energetiques": "Taux de Passoires Energ√©tiques (en %)",
        "etiquette_dpe_frequente": "Etiquette DPE la plus fr√©quente",
    }

    # Couleurs et ic√¥nes pour les KPI
    colors = {
        "conso_energetique_moyenne": "#AED6F1",  # Bleu
        "pct_logements_au_dessus_moyenne": "#ABEBC6 ",  # Vert
        "taux_passoires_energetiques": "#f0b27a",  # Orange
        "etiquette_dpe_frequente": "#d5d8dc",  # Gris
    }

    icons = {
        "conso_energetique_moyenne": "üîã",  # Batterie
        "pct_logements_au_dessus_moyenne": "üè†",  # Maison
        "taux_passoires_energetiques": "‚ö°",  # √âclair
        "etiquette_dpe_frequente": "üè∑Ô∏è",  # √âtiquette
    }

    # Disposer les KPI en colonnes
    col1, col2, col3, col4 = st.columns(4)
    cols = [col1, col2, col3, col4]
    kpi_keys = list(kpis.keys())

    for i in range(4):
        with cols[i]:
            value = kpis[kpi_keys[i]]
            # Limiter l'affichage des chiffres √† 10 chiffres significatifs
            if isinstance(value, (int, float)):
                value = f"{value:.7g}"
            st.markdown(
                f'<div style="background-color: {colors[kpi_keys[i]]}; padding: 20px; border-radius: 5px; text-align: center; height: 150px; display: flex; flex-direction: column; justify-content: center;">'
                f"<h4>{icons[kpi_keys[i]]} {kpis_readable[kpi_keys[i]]}</h4>"
                f"<h4>{value}</h4>"
                f"</div>",
                unsafe_allow_html=True,
            )

    st.markdown("---")
